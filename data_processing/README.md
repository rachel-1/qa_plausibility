In this project, we used a dataset collected by Qbot (as presented in [Information Maximizing Visual Question Generation](https://arxiv.org/abs/1903.11207)), which contained questions generated by the bot about images on social media, as well as the response of the original poster and the image itself. This initial dataset had been annotated by Amazon Mechanical Turk workers to add the true answer to the question asked. However, in many cases the bot-generated question was invalid and/or the social media user was confused or deliberately unhelpful. This led to inconsistent annotations by the Amazon Mechanical Turk workers. To address this, we re-annotated the data with more detailed instructions, a qualifying task and finer-grained questions for the AMT workers. For privacy reasons, we are not releasing the dataset at this time. However, the steps we used can be traced through the Jupyter notebooks as follows (noting that our data links have been replaced with `TODO` where necessary):

1. **Raw Data Filtering and Tokenization**: process the raw social media data.
2. **Generating MTurk Splits**: split out the data to be annotated by new Amazon Mechanical Turk workers, based on initial labels from original Amazon Mechanical Turkers.
3. **Data Annotation**: create and post the AMT tasks.
4. **AMT Annotation Analysis**: manually QA the results of the AMT tasks.
5. **Annotated Data Filtering and Tokenization**: once data has been fully annotated by Amazon Mechanical Turk workers, clean up the results.
6. **Generate Splits**: split the labeled data into train/val/test in order to train the model, and write out the unlabeled data to be cleaned by the trained model. 
7. **Model Error Analysis**: given an `eval.csv` output from evaluating a trained model, view the metrics of the model and visualize specific examples from various categories.
